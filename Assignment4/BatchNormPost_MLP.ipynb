{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_Spring_2022/blob/main/MLP_Fmnist_Saver_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_iYcla4kCX67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgna3kY6CX67",
        "outputId": "131758d1-de92-49bc-ebd3-1515cf035a98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JodgHy9nCX68",
        "outputId": "efefd691-8e20-4bf5-926a-20182510beec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # Load MNIST or FMNIST\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "\n",
        "# Display randomly selected data\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important\n",
        "* Always have a validation set, the procedure to create validation or dev set is by performing random sample without replacement on train set and then only using that fraction as dev set. \n",
        "* Simple approach is to set some K samples, you can extract them from start, mid or end.\n",
        "* Imagine validation set that partially approximates test set distribution and we assume our model would produce identical results when we test it on test set.\n",
        "* Always optimize your hyperparameters by looking at performance on validation set and not test set.\n",
        "* Do not touch test set, we have this to test how our model would work on unseen data."
      ],
      "metadata": {
        "id": "PowjAHuw-wm7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIRI-uLoCX69",
        "outputId": "7dca137b-2081-4c9f-9d7a-7f38e69d1ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set is 50000 samples\n",
            "every train example is 28 by 28\n",
            "size of validation set is 10000 samples\n",
            "every validation example is 28 by 28\n",
            "size of training set is 50000 samples\n",
            "every train example has 784 features\n",
            "size of validation set is 10000 samples\n",
            "every validation example has 784 features\n"
          ]
        }
      ],
      "source": [
        "# Split train dataset into train and validation\n",
        "X_val = X_train[50000:60000]\n",
        "X_train = X_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
        "\n",
        "X_train = X_train.reshape(50000, 28*28)\n",
        "X_val = X_val.reshape(10000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example has\", str(X_val.shape[1]), \"features\")\n",
        "\n",
        "# Split dataset into batches\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "#test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Points to remember\n",
        "* If using any type of neural network, normalize your input between 0-1.\n",
        "* One can use various procedures to achieve this, divide by largest value (for images we use 255), subtract mean from data and then normalize, one can even augment them and use other steps for normalization.\n",
        "* Normalization is important step, one could observe significant boost in performance just by having better normalization scheme.\n",
        "* For targets we always use one-hot encodings."
      ],
      "metadata": {
        "id": "VdMEIaFKAscU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDyZ8bZjCX69",
        "outputId": "195a560e-6b25-4ca5-9c2e-07dbd390223d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Normalize Data\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "X_test = X_test/255\n",
        "# X_train[0]\n",
        "np.max(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIIy313CX69",
        "outputId": "a591b40f-bd0c-49c0-efd2-4be9ddf72518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "size_input = X_train.shape[1]\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 128\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "\n",
        "number_of_train_examples = X_train.shape[0]\n",
        "number_of_test_examples = X_test.shape[0]\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(tf.shape(y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importance of weight initialization\n",
        "\n",
        "* One reason backprop based models can perform bettter lies with the weight initialization method, one important point one should remember is that, if yur weights are initialized to be too high or low, backprop would struggle.\n",
        "* Hence one should always carefully initialize weights of your model, below i have shown approach with random_normal, one can use random_uniform, truncated version of both, Xavier init and orthogonal. \n",
        "* You will find modern day NNs have achieved stable and better performance by simply switching to better init and majority of cases Xavier or Orthogonal works best.\n",
        "* Always initialize your bias using zero or some small constant (ideally 0.01 or less works better). We use bias to shift the activation and in some cases it can stabalize learning, but having large bias can cause negative results.\n",
        "\n",
        "# Loss function\n",
        "\n",
        "* We will always cross-entropy loss for classification.\n",
        "\n",
        "* tf softmax,\n",
        "loss= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf)), this function is simply saying that it will calculate softmax for you, simply provide logits to it. \n",
        "\n",
        "* In other output of your forward pass directly goes this function. Now this operator will calculate or apply softmax over prediction or logits and calculate cross-entropy between prediction and target. I am using reduce_mean since we apply this over batches.\n",
        "* Second is using keras\n",
        "Method 1 :- This function requires logits, hence same as above you will pass logits or output variable to this function. Now remember you need from_logits = True, for this to work.\n",
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "loss_x = cce(y_true_tf, y_pred_tf) \n",
        "\n",
        "* Method 2:- In this we will apply softmax to output function and then pass to CCE loss.\n",
        "So the approach is \n",
        "output = tf.nn.softmax(output)\n",
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "loss_x = cce(y_true_tf, y_pred_tf) "
      ],
      "metadata": {
        "id": "U7KCVarVCVPW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "obN7WPLpCX69"
      },
      "outputs": [],
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        " def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of the 1st hidden layer\n",
        "    size_hidden2: int, size of the 2nd hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "    \n",
        "    # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1],stddev=0.1)) # Xavier(Fan-in fan-out) and Orthogonal\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
        "    \n",
        "    # Initialize weights between input layer and 1st hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    \n",
        "    # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "     # Initialize weights between 2nd hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output],stddev=0.1))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "    \n",
        "    self.g1 = tf.Variable(tf.random.normal([1, self.size_hidden1], stddev = 0.1))    \n",
        "    self.beta1= tf.Variable(tf.random.normal([1, self.size_hidden1], stddev = 0.1))    \n",
        "    self.g2 = tf.Variable(tf.random.normal([1, self.size_hidden2], stddev = 0.1))    \n",
        "    self.beta2= tf.Variable(tf.random.normal([1, self.size_hidden2], stddev = 0.1))    \n",
        "    self.g3 = tf.Variable(tf.random.normal([1, self.size_hidden3], stddev = 0.1))    \n",
        "    self.beta3= tf.Variable(tf.random.normal([1, self.size_hidden3], stddev = 0.1))    \n",
        "   \n",
        "    self.m1 = tf.Variable(tf.random.normal([1, self.size_hidden1], stddev = 0.1))    \n",
        "    self.std1= tf.Variable(tf.random.normal([1, self.size_hidden1], stddev = 0.1))    \n",
        "    self.m2 = tf.Variable(tf.random.normal([1, self.size_hidden2], stddev = 0.1))    \n",
        "    self.std2= tf.Variable(tf.random.normal([1, self.size_hidden2], stddev = 0.1))    \n",
        "    self.m3 = tf.Variable(tf.random.normal([1, self.size_hidden3], stddev = 0.1))    \n",
        "    self.std3= tf.Variable(tf.random.normal([1, self.size_hidden3], stddev = 0.1))   \n",
        "    self.e=0.1\n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4,self.g1,self.beta1,self.g2,self.beta2,self.g3,self.beta3]\n",
        "  \n",
        " def forward(self, X,train=True):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X,train)\n",
        "    else:\n",
        "      self.y = self.compute_output(X,train)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        " def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    loss_x = cce(y_true_tf, y_pred_tf)\n",
        "    # Use keras or tf_softmax, both should work for any given model\n",
        "    #loss_x = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf))\n",
        "    \n",
        "    return loss_x\n",
        "\n",
        " def backward(self, X_train, y_train, opti):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = opti\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "        \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "           \n",
        " def compute_output(self, X,train=True):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #X_tf = X\n",
        "\n",
        "    if(train):\n",
        "    \n",
        "      h3 = self.BatchNormTrain(X_tf)\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "      return (output)\n",
        "\n",
        "    else:\n",
        "      h3 = self.BatchNormTest(X_tf)\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "      return (output)\n",
        "\n",
        "      \n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
        "    # Second add tf.Softmax(output) and then return this variable\n",
        "\n",
        " def BatchNormTrain(self,X_tf):\n",
        "\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    h1 = (self.g1*(h1-np.mean(h1, 0))/(np.std(h1, 0) + tf.math.sqrt(self.e)))+self.beta1\n",
        "    \n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    h2 = (self.g2*(h2-np.mean(h2, 0))/(np.std(h2, 0) + tf.math.sqrt(self.e)))+self.beta2\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "    h3 = (self.g3*(h3-np.mean(h3, 0))/(np.std(h3, 0) + tf.math.sqrt(self.e)))+self.beta3\n",
        "    \n",
        "    return h3\n",
        " def BatchNormTest(self,X_tf):\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    h1 = (self.g1*(h1-self.m1)/self.std1)+self.beta1\n",
        "    \n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    h2 = (self.g2*(h2-self.m2)/self.std2)+self.beta2\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "    h3 = (self.g3*(h3-self.m3)/self.std3)+self.beta3\n",
        " \n",
        "    return h3\n",
        "\n",
        "\n",
        " def initMeanAndVarianceForEntireTestSet(self, X):\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    self.m1=np.mean(h1, 0)\n",
        "    self.std1=np.std(h1, 0)+ tf.math.sqrt(self.e)\n",
        "    h1 = (self.g1*(h1-self.m1)/self.std1)+self.beta1\n",
        "\n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    self.m2=np.mean(h2, 0)\n",
        "    self.std2=np.std(h2, 0)+ tf.math.sqrt(self.e)\n",
        "    h2= (self.g2*(h2-self.m2)/self.std2)+self.beta2\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "    self.m3=np.mean(h3, 0)\n",
        "    self.std3=np.std(h3, 0)+ tf.math.sqrt(self.e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  def stderr(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate standard error\n",
        "#      \"\"\"\n",
        "#     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "#     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "#     std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "#     return std_err \n",
        "\n",
        "\n",
        "#  def var(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate variance \n",
        "#      \"\"\"\n",
        "#     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "#     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "#     variance = (std_dev**2) # calculate variance\n",
        "#     return variance \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = [99998,321,878,7,56,876,6666,7777,3452,5]\n",
        "NUM_EPOCHS = 40\n",
        "opti = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for x in seed:\n",
        "  print('For Seed',x,':')\n",
        "\n",
        "  #Default mode\n",
        "  mlp_on_default = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "  #hidden2 = MLP(size_hidden2, size_hidden2, size_output, device='gpu')\n",
        "  time_start = time.time()\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "    lt = 0\n",
        "    acc = 0\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(x)).batch(64)\n",
        "    accuracies = []\n",
        "    for inputs, outputs in train_ds:\n",
        "      preds = mlp_on_default.forward(inputs)\n",
        "      loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "      acc = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "      lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "      mlp_on_default.backward(inputs, outputs,opti)\n",
        "    mlp_on_default.initMeanAndVarianceForEntireTestSet(X_train)\n",
        "    Accpred = mlp_on_default.forward(X_train,False)\n",
        "    cat_acc = tf.metrics.CategoricalAccuracy()\n",
        "    accuracies.append(cat_acc(Accpred, y_train))\n",
        "    ValAccuracies = []\n",
        "    Accpred = mlp_on_default.forward(X_val,False)\n",
        "    cat_acc = tf.metrics.CategoricalAccuracy()\n",
        "    ValAccuracies.append(cat_acc(Accpred, y_val))\n",
        "    if((epoch+1)%2 == 0):\n",
        "      print('Number of Epoch = {} - Average Loss:= {} Validation Accuracy:= {} Training Accuracy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0],np.mean(ValAccuracies)*100,np.mean(accuracies)*100))\n",
        "\n",
        "  time_taken = time.time() - time_start\n",
        "  print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "  #inference\n",
        "  test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  #test_loss_total = 0.0\n",
        "  test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(25, seed=epoch*(x)).batch(64)\n",
        "  cat_acc = tf.metrics.CategoricalAccuracy()\n",
        "  accuracies = []\n",
        "  mlp_on_default.initMeanAndVarianceForEntireTestSet(X_train)\n",
        "  for inputs, outputs in test_ds:\n",
        "    preds = mlp_on_default.forward(inputs,False)\n",
        "    test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "    cat_acc = tf.metrics.CategoricalAccuracy()  \n",
        "    accuracies.append(cat_acc(preds, outputs))\n",
        "\n",
        "\n",
        "  print('Inference Loss: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))\n",
        "  print('Inference Accuracy: {:.4f}'.format(np.mean(accuracies)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HFEAVf5MwZdy",
        "outputId": "443b90bf-487d-4749-ae68-fe543e49fc2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Seed 99998 :\n",
            "Number of Epoch = 2 - Average Loss:= 0.010805626220703125 Validation Accuracy:= 61.229997873306274 Training Accuracy:= 61.60399913787842\n",
            "Number of Epoch = 4 - Average Loss:= 0.005471182250976562 Validation Accuracy:= 75.34000277519226 Training Accuracy:= 75.71600079536438\n",
            "Number of Epoch = 6 - Average Loss:= 0.004427751770019531 Validation Accuracy:= 80.8899998664856 Training Accuracy:= 81.86799883842468\n",
            "Number of Epoch = 8 - Average Loss:= 0.0037790463256835937 Validation Accuracy:= 82.9800009727478 Training Accuracy:= 83.99800062179565\n",
            "Number of Epoch = 10 - Average Loss:= 0.0034316485595703126 Validation Accuracy:= 84.36999917030334 Training Accuracy:= 85.29000282287598\n",
            "Number of Epoch = 12 - Average Loss:= 0.003190088806152344 Validation Accuracy:= 85.4200005531311 Training Accuracy:= 86.33000254631042\n",
            "Number of Epoch = 14 - Average Loss:= 0.0030170492553710936 Validation Accuracy:= 85.6000006198883 Training Accuracy:= 86.84599995613098\n",
            "Number of Epoch = 16 - Average Loss:= 0.0028558587646484376 Validation Accuracy:= 86.03000044822693 Training Accuracy:= 87.65000104904175\n",
            "Number of Epoch = 18 - Average Loss:= 0.002730483093261719 Validation Accuracy:= 86.58999800682068 Training Accuracy:= 88.0620002746582\n",
            "Number of Epoch = 20 - Average Loss:= 0.0026364718627929686 Validation Accuracy:= 86.64000034332275 Training Accuracy:= 88.23000192642212\n",
            "Number of Epoch = 22 - Average Loss:= 0.0025377569580078124 Validation Accuracy:= 86.69000267982483 Training Accuracy:= 88.18399906158447\n",
            "Number of Epoch = 24 - Average Loss:= 0.002446120910644531 Validation Accuracy:= 87.05000281333923 Training Accuracy:= 88.76000046730042\n",
            "Number of Epoch = 26 - Average Loss:= 0.0023762020874023436 Validation Accuracy:= 87.48999834060669 Training Accuracy:= 89.50600028038025\n",
            "Number of Epoch = 28 - Average Loss:= 0.0023034115600585937 Validation Accuracy:= 87.27999925613403 Training Accuracy:= 89.62200284004211\n",
            "Number of Epoch = 30 - Average Loss:= 0.0022339804077148437 Validation Accuracy:= 87.58999705314636 Training Accuracy:= 89.9839997291565\n",
            "Number of Epoch = 32 - Average Loss:= 0.0021750776672363283 Validation Accuracy:= 87.48000264167786 Training Accuracy:= 90.20799994468689\n",
            "Number of Epoch = 34 - Average Loss:= 0.0021331695556640624 Validation Accuracy:= 87.61000037193298 Training Accuracy:= 90.43599963188171\n",
            "Number of Epoch = 36 - Average Loss:= 0.0020611317443847655 Validation Accuracy:= 87.87000179290771 Training Accuracy:= 90.69799780845642\n",
            "Number of Epoch = 38 - Average Loss:= 0.0020173365783691406 Validation Accuracy:= 87.76999711990356 Training Accuracy:= 91.04800224304199\n",
            "Number of Epoch = 40 - Average Loss:= 0.0019681317138671873 Validation Accuracy:= 87.62999773025513 Training Accuracy:= 90.89400172233582\n",
            "\n",
            "Total time taken (in seconds): 716.41\n",
            "Inference Loss: 0.0029\n",
            "Inference Accuracy: 87.2033\n",
            "For Seed 321 :\n",
            "Number of Epoch = 2 - Average Loss:= 0.009136341552734375 Validation Accuracy:= 64.85000252723694 Training Accuracy:= 65.61200022697449\n",
            "Number of Epoch = 4 - Average Loss:= 0.005174337768554687 Validation Accuracy:= 77.7999997138977 Training Accuracy:= 78.25599908828735\n",
            "Number of Epoch = 6 - Average Loss:= 0.004272266235351562 Validation Accuracy:= 81.80000185966492 Training Accuracy:= 82.24999904632568\n",
            "Number of Epoch = 8 - Average Loss:= 0.003751238098144531 Validation Accuracy:= 83.45000147819519 Training Accuracy:= 84.0499997138977\n",
            "Number of Epoch = 10 - Average Loss:= 0.0034320941162109377 Validation Accuracy:= 84.64000225067139 Training Accuracy:= 85.22199988365173\n",
            "Number of Epoch = 12 - Average Loss:= 0.0031958590698242186 Validation Accuracy:= 85.5400025844574 Training Accuracy:= 86.21799945831299\n",
            "Number of Epoch = 14 - Average Loss:= 0.003038726806640625 Validation Accuracy:= 86.05999946594238 Training Accuracy:= 86.98599934577942\n",
            "Number of Epoch = 16 - Average Loss:= 0.002917767028808594 Validation Accuracy:= 86.23999953269958 Training Accuracy:= 87.44800090789795\n",
            "Number of Epoch = 18 - Average Loss:= 0.0028023095703125 Validation Accuracy:= 86.39000058174133 Training Accuracy:= 87.76999711990356\n",
            "Number of Epoch = 20 - Average Loss:= 0.002704648742675781 Validation Accuracy:= 86.6599977016449 Training Accuracy:= 88.19199800491333\n",
            "Number of Epoch = 22 - Average Loss:= 0.002614872131347656 Validation Accuracy:= 86.73999905586243 Training Accuracy:= 88.51400017738342\n",
            "Number of Epoch = 24 - Average Loss:= 0.002537526397705078 Validation Accuracy:= 87.22000122070312 Training Accuracy:= 88.85400295257568\n",
            "Number of Epoch = 26 - Average Loss:= 0.0024604107666015623 Validation Accuracy:= 87.30000257492065 Training Accuracy:= 89.28800225257874\n",
            "Number of Epoch = 28 - Average Loss:= 0.002380065155029297 Validation Accuracy:= 87.66000270843506 Training Accuracy:= 89.63800072669983\n",
            "Number of Epoch = 30 - Average Loss:= 0.0023099241638183596 Validation Accuracy:= 87.33000159263611 Training Accuracy:= 89.68600034713745\n",
            "Number of Epoch = 32 - Average Loss:= 0.0022497064208984374 Validation Accuracy:= 87.6200020313263 Training Accuracy:= 90.02799987792969\n",
            "Number of Epoch = 34 - Average Loss:= 0.002190880432128906 Validation Accuracy:= 87.23999857902527 Training Accuracy:= 89.84000086784363\n",
            "Number of Epoch = 36 - Average Loss:= 0.0021290509033203126 Validation Accuracy:= 87.80999779701233 Training Accuracy:= 90.65399765968323\n",
            "Number of Epoch = 38 - Average Loss:= 0.0020776734924316405 Validation Accuracy:= 87.94999718666077 Training Accuracy:= 90.78400135040283\n",
            "Number of Epoch = 40 - Average Loss:= 0.0020205357360839845 Validation Accuracy:= 87.66000270843506 Training Accuracy:= 91.01799726486206\n",
            "\n",
            "Total time taken (in seconds): 682.70\n",
            "Inference Loss: 0.0028\n",
            "Inference Accuracy: 87.3220\n",
            "For Seed 878 :\n",
            "Number of Epoch = 2 - Average Loss:= 0.009559396362304688 Validation Accuracy:= 66.08999967575073 Training Accuracy:= 66.81399941444397\n",
            "Number of Epoch = 4 - Average Loss:= 0.005047428588867187 Validation Accuracy:= 76.77000164985657 Training Accuracy:= 77.26399898529053\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0109b0bb8499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_total_gpu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmlp_on_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmlp_on_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mmlp_on_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmlp_on_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitMeanAndVarianceForEntireTestSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mAccpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_on_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6cbb1d48e745>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X_train, y_train, opti)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m       \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6cbb1d48e745>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mloss_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Use keras or tf_softmax, both should work for any given model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m#loss_x = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    143\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   return backend.categorical_crossentropy(\n\u001b[0;32m-> 1790\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   5097\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5098\u001b[0m     return tf.nn.softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 5099\u001b[0;31m         labels=target, logits=output, axis=axis)\n\u001b[0m\u001b[1;32m   5100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5101\u001b[0m   if (not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable)) and\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, axis, name)\u001b[0m\n\u001b[1;32m   4007\u001b[0m   \"\"\"\n\u001b[1;32m   4008\u001b[0m   return softmax_cross_entropy_with_logits_v2_helper(\n\u001b[0;32m-> 4009\u001b[0;31m       labels=labels, logits=logits, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   4010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                 instructions)\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2_helper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \u001b[0;31m# The output cost shape should be the input minus axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4118\u001b[0m     output_shape = array_ops.slice(input_shape, [0],\n\u001b[0;32m-> 4119\u001b[0;31m                                    [math_ops.subtract(input_rank, 1)])\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m   \"\"\"\n\u001b[0;32m-> 1119\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   9576\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9577\u001b[0m       return _slice_eager_fallback(\n\u001b[0;32m-> 9578\u001b[0;31m           input, begin, size, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   9579\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9580\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice_eager_fallback\u001b[0;34m(input, begin, size, name, ctx)\u001b[0m\n\u001b[1;32m   9597\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_slice_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9598\u001b[0m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9599\u001b[0;31m   \u001b[0m_attr_Index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_inputs_Index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9600\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inputs_Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9601\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         tensor = ops.convert_to_tensor(\n\u001b[0;32m--> 265\u001b[0;31m             t, dtype, preferred_dtype=default_dtype, ctx=ctx)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m       \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1543\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1546\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__ne__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;34m\"\"\"Returns True iff self != other.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   \u001b[0;31m# \"If a class that overrides __eq__() needs to retain the implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pOnhvVlUCX6-",
        "outputId": "59cc83da-5bdf-4eb0-b458-2be920459218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 0.8292\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.0070905438232421875 \n",
            "\n",
            "Validation Accuracy: 0.8208\n",
            "\n",
            "Train Accuracy: 0.8545\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.0035109307861328127 \n",
            "\n",
            "Validation Accuracy: 0.8450\n",
            "\n",
            "Train Accuracy: 0.8680\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.0031131005859375 \n",
            "\n",
            "Validation Accuracy: 0.8561\n",
            "\n",
            "Train Accuracy: 0.8771\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.0028826300048828126 \n",
            "\n",
            "Validation Accuracy: 0.8634\n",
            "\n",
            "Train Accuracy: 0.8849\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.0026978872680664063 \n",
            "\n",
            "Validation Accuracy: 0.8685\n",
            "\n",
            "Train Accuracy: 0.8889\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.0025520314025878907 \n",
            "\n",
            "Validation Accuracy: 0.8685\n",
            "\n",
            "Train Accuracy: 0.8960\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.0024296630859375 \n",
            "\n",
            "Validation Accuracy: 0.8734\n",
            "\n",
            "Train Accuracy: 0.8972\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.002314106750488281 \n",
            "\n",
            "Validation Accuracy: 0.8728\n",
            "\n",
            "Train Accuracy: 0.9043\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.002208934631347656 \n",
            "\n",
            "Validation Accuracy: 0.8762\n",
            "\n",
            "Train Accuracy: 0.9070\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.0021014094543457033 \n",
            "\n",
            "Validation Accuracy: 0.8750\n",
            "\n",
            "Total time taken (in seconds): 190.94\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "opti = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "    \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(128)\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  for inputs, outputs in train_ds:\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs) \n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs, opti)\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "  print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
        "  \n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "        \n",
        "time_taken = time.time() - time_start\n",
        "    \n",
        "# Validate model\n",
        "    \n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "opti = tf.keras.optimizers.SGD(learning_rate = 0.1, momentum=0.9)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "    \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(128)\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  for inputs, outputs in train_ds:\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs) \n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs, opti)\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "  print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
        "  \n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "\n",
        "        \n",
        "time_taken = time.time() - time_start\n",
        "    \n",
        "# Validate model\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wP34CXEreaHC",
        "outputId": "9f27ac3e-2951-4e20-d1f2-9d5675981ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 0.8708\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.004519539489746094 \n",
            "\n",
            "Validation Accuracy: 0.8588\n",
            "\n",
            "Train Accuracy: 0.8870\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.0028923043823242188 \n",
            "\n",
            "Validation Accuracy: 0.8687\n",
            "\n",
            "Train Accuracy: 0.8951\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.0025675372314453125 \n",
            "\n",
            "Validation Accuracy: 0.8733\n",
            "\n",
            "Train Accuracy: 0.8996\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.0023671160888671873 \n",
            "\n",
            "Validation Accuracy: 0.8758\n",
            "\n",
            "Train Accuracy: 0.9065\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.0022008470153808595 \n",
            "\n",
            "Validation Accuracy: 0.8756\n",
            "\n",
            "Train Accuracy: 0.9089\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.002058603668212891 \n",
            "\n",
            "Validation Accuracy: 0.8753\n",
            "\n",
            "Train Accuracy: 0.9155\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.0019298921203613282 \n",
            "\n",
            "Validation Accuracy: 0.8775\n",
            "\n",
            "Train Accuracy: 0.9155\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.0018463410949707032 \n",
            "\n",
            "Validation Accuracy: 0.8767\n",
            "\n",
            "Train Accuracy: 0.9152\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.001746738739013672 \n",
            "\n",
            "Validation Accuracy: 0.8765\n",
            "\n",
            "Train Accuracy: 0.9175\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.0016593826293945313 \n",
            "\n",
            "Validation Accuracy: 0.8753\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-697acb4daea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_on_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0mtest_loss_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loss_total\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMLP_after_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLP_after_check' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RMSProp\n",
        "\n",
        "* Maintain a moving average of the square of gradients\n",
        "* Divide the gradient by the root of this moving average"
      ],
      "metadata": {
        "id": "rWaSewweLJ0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "opti = tf.keras.optimizers.RMSprop(learning_rate = 1e-3)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "    \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(128)\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  for inputs, outputs in train_ds:\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs) \n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs, opti)\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "  print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
        "  \n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "        \n",
        "time_taken = time.time() - time_start\n",
        "    \n",
        "# Validate model\n",
        "    \n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LYIiTY9CduSh",
        "outputId": "85b0539c-2021-4d1b-92e2-6cc32f0b8144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 0.8524\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.004470570068359375 \n",
            "\n",
            "Validation Accuracy: 0.8475\n",
            "\n",
            "Train Accuracy: 0.8586\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.0030924380493164063 \n",
            "\n",
            "Validation Accuracy: 0.8457\n",
            "\n",
            "Train Accuracy: 0.8832\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.002732566833496094 \n",
            "\n",
            "Validation Accuracy: 0.8716\n",
            "\n",
            "Train Accuracy: 0.8878\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.0024964035034179687 \n",
            "\n",
            "Validation Accuracy: 0.8725\n",
            "\n",
            "Train Accuracy: 0.8959\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.002327974395751953 \n",
            "\n",
            "Validation Accuracy: 0.8769\n",
            "\n",
            "Train Accuracy: 0.8975\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.002187594757080078 \n",
            "\n",
            "Validation Accuracy: 0.8749\n",
            "\n",
            "Train Accuracy: 0.9050\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.0020711753845214843 \n",
            "\n",
            "Validation Accuracy: 0.8805\n",
            "\n",
            "Train Accuracy: 0.9016\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.0019677088928222656 \n",
            "\n",
            "Validation Accuracy: 0.8729\n",
            "\n",
            "Train Accuracy: 0.9134\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.0018597050476074218 \n",
            "\n",
            "Validation Accuracy: 0.8813\n",
            "\n",
            "Train Accuracy: 0.8949\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.0017836886596679688 \n",
            "\n",
            "Validation Accuracy: 0.8620\n",
            "\n",
            "Total time taken (in seconds): 191.27\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adam\n",
        "* Combine RMSprop with momentum\n",
        "* Default optimizer in many applications\n",
        "* In some scenarios leads to poor performance such as Continual learning, lifelong learning, metalearning"
      ],
      "metadata": {
        "id": "1wPc6gzpKLRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "opti = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "    \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(128)\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  for inputs, outputs in train_ds:\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs) \n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs, opti)\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "  print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
        "  \n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "        \n",
        "time_taken = time.time() - time_start\n",
        "    \n",
        "# Validate model\n",
        "    \n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NRjrGeh0dmy4",
        "outputId": "4b671ff9-596b-489e-e930-c9863ddc685a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 0.8039\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.007583687744140625 \n",
            "\n",
            "Validation Accuracy: 0.7970\n",
            "\n",
            "Train Accuracy: 0.8350\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.004100390014648438 \n",
            "\n",
            "Validation Accuracy: 0.8247\n",
            "\n",
            "Train Accuracy: 0.8481\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.0036029278564453124 \n",
            "\n",
            "Validation Accuracy: 0.8397\n",
            "\n",
            "Train Accuracy: 0.8569\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.003350390625 \n",
            "\n",
            "Validation Accuracy: 0.8485\n",
            "\n",
            "Train Accuracy: 0.8631\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.0031754852294921874 \n",
            "\n",
            "Validation Accuracy: 0.8533\n",
            "\n",
            "Train Accuracy: 0.8676\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.003048553161621094 \n",
            "\n",
            "Validation Accuracy: 0.8583\n",
            "\n",
            "Train Accuracy: 0.8716\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.0029451785278320312 \n",
            "\n",
            "Validation Accuracy: 0.8604\n",
            "\n",
            "Train Accuracy: 0.8746\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.0028560934448242188 \n",
            "\n",
            "Validation Accuracy: 0.8632\n",
            "\n",
            "Train Accuracy: 0.8778\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.002779222412109375 \n",
            "\n",
            "Validation Accuracy: 0.8651\n",
            "\n",
            "Train Accuracy: 0.8796\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.002712095947265625 \n",
            "\n",
            "Validation Accuracy: 0.8679\n",
            "\n",
            "Total time taken (in seconds): 91.86\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nadam Optimizer\n",
        "* Combine Adam with Nesterov momentum\n",
        "* In somecases (image segmentation, object detection) it performs stably and leads to faster convergence "
      ],
      "metadata": {
        "id": "wFt--2EnIpoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "opti = tf.keras.optimizers.Nadam(learning_rate = 1e-4)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "    \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(128)\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  for inputs, outputs in train_ds:\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs) \n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs, opti)\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "  print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
        "  \n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "        \n",
        "time_taken = time.time() - time_start\n",
        "    \n",
        "# Validate model\n",
        "    \n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qa4m43RFgeE1",
        "outputId": "d820a316-5156-4b0a-912d-6f757bcecb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 0.8079\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.007469556884765625 \n",
            "\n",
            "Validation Accuracy: 0.7991\n",
            "\n",
            "Train Accuracy: 0.8344\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.004099525146484375 \n",
            "\n",
            "Validation Accuracy: 0.8271\n",
            "\n",
            "Train Accuracy: 0.8484\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.0036003802490234375 \n",
            "\n",
            "Validation Accuracy: 0.8427\n",
            "\n",
            "Train Accuracy: 0.8568\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.003330947265625 \n",
            "\n",
            "Validation Accuracy: 0.8523\n",
            "\n",
            "Train Accuracy: 0.8645\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.0031479156494140623 \n",
            "\n",
            "Validation Accuracy: 0.8582\n",
            "\n",
            "Train Accuracy: 0.8686\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.003007879943847656 \n",
            "\n",
            "Validation Accuracy: 0.8600\n",
            "\n",
            "Train Accuracy: 0.8734\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.002898348388671875 \n",
            "\n",
            "Validation Accuracy: 0.8628\n",
            "\n",
            "Train Accuracy: 0.8766\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.0028031634521484376 \n",
            "\n",
            "Validation Accuracy: 0.8660\n",
            "\n",
            "Train Accuracy: 0.8801\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.002720559387207031 \n",
            "\n",
            "Validation Accuracy: 0.8682\n",
            "\n",
            "Train Accuracy: 0.8828\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.0026505709838867187 \n",
            "\n",
            "Validation Accuracy: 0.8699\n",
            "\n",
            "Total time taken (in seconds): 177.53\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving your model weights or parameters\n",
        "* It is always advisable to save your model checkpoints every k epochs. Look at Saver object in tensorflow/keras.\n",
        "* Visualize your model performance using tensorboard.\n",
        "\n",
        "# Steps to save model weights using pickle\n",
        "* Save your model(trainable variables), in our case self.variables into a pickle file.\n",
        "* Load saved file\n",
        "* Redefine model\n",
        "* Load weights\n",
        "* Re-train or test your model\n"
      ],
      "metadata": {
        "id": "2O5EAiXOHQir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import pickle\n",
        "variables_old = mlp_on_cpu.variables\n",
        "with open('weights.pickle', 'wb') as handle:\n",
        "    pickle.dump(variables_old, handle)"
      ],
      "metadata": {
        "id": "-gtwqTXnjW30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('weights.pickle', 'rb') as handle:\n",
        "    b = pickle.load(handle)"
      ],
      "metadata": {
        "id": "l9Jc34APkghg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP_check(object):\n",
        " def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of the 1st hidden layer\n",
        "    size_hidden2: int, size of the 2nd hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "    \n",
        "    # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1],stddev=0.1)) # Xavier(Fan-in fan-out) and Orthogonal\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
        "    \n",
        "    # Initialize weights between input layer and 1st hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    \n",
        "    # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "     # Initialize weights between 2nd hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output],stddev=0.1))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "  \n",
        " def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        " def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    loss_x = cce(y_true_tf, y_pred_tf)\n",
        "    # Use keras or tf_softmax, both should work for any given model\n",
        "    #loss_x = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf))\n",
        "    \n",
        "    return loss_x\n",
        "\n",
        " def backward(self, X_train, y_train, opti):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = opti\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "        \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "           \n",
        " def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #X_tf = X\n",
        "    \n",
        "    # Compute values in hidden layers\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    \n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "\n",
        "    # Compute output\n",
        "    output = tf.matmul(h3, self.W4) + self.b4\n",
        "    \n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
        "    # Second add tf.Softmax(output) and then return this variable\n",
        "    return (output)\n",
        "\n"
      ],
      "metadata": {
        "id": "gXRQs7HWtgVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_after_check = MLP_check(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "W = MLP_after_check.variables[0]\n",
        "W.assign(b[0])\n",
        "W1 = MLP_after_check.variables[1]\n",
        "W1.assign(b[1])\n",
        "W2 = MLP_after_check.variables[2]\n",
        "W2.assign(b[2])\n",
        "W3 = MLP_after_check.variables[3]\n",
        "W3.assign(b[3])\n",
        "B = MLP_after_check.variables[4]\n",
        "B.assign(b[4])\n",
        "B1 = MLP_after_check.variables[5]\n",
        "B1.assign(b[5])\n",
        "B2 = MLP_after_check.variables[6]\n",
        "B2.assign(b[6])\n",
        "B3 = MLP_after_check.variables[7]\n",
        "B3.assign(b[7])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg3MXT4Stqan",
        "outputId": "b28fe21f-a5b1-4b29-c6ac-5df6e16b6eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(1, 10) dtype=float32, numpy=\n",
              "array([[ 0.31285602, -0.56231725,  0.6267492 ,  0.08308472,  0.28097275,\n",
              "        -0.26073027,  0.27095762, -0.27032936,  0.09554584, -0.5767893 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eNKeELWCX6_",
        "outputId": "71f0f0a3-2d1e-42d1-dd74-0c614d9dc858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4b3b84a41d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#test_loss_total = 0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_on_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;31m#test_loss_total = test_loss_total + MLP_after_check.loss(preds, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2b73673f1fda>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpu:0'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'gpu'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2b73673f1fda>\u001b[0m in \u001b[0;36mcompute_output\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mz3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3712\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3713\u001b[0m         return gen_math_ops.mat_mul(\n\u001b[0;32m-> 3714\u001b[0;31m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   3715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6013\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6015\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   6016\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6017\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_prediction = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  #test_loss_total = test_loss_total + MLP_after_check.loss(preds, outputs)\n",
        "print('Test loss: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))\n",
        "\n",
        "# Test model\n",
        "preds_test = MLP_after_check.forward(X_test)\n",
        "preds_test = tf.nn.softmax(preds_test)\n",
        "correct_prediction = tf.equal(tf.argmax(preds_test, 1), tf.argmax(y_test, 1))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "cur_test_acc = accuracy.numpy()\n",
        "print('\\nTest Accuracy: {:.2f}'.format(cur_test_acc))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "5DRomYsUCX6_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYsXWqI_CX6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966feeab-5387-4f48-9bff-2a6449c628c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.3250\n",
            "\n",
            "Test Accuracy: 0.87\n"
          ]
        }
      ],
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_prediction = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "print('Test loss: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))\n",
        "\n",
        "# Test model\n",
        "preds_test = mlp_on_cpu.forward(X_test)\n",
        "preds_test = tf.nn.softmax(preds_test)\n",
        "correct_prediction = tf.equal(tf.argmax(preds_test, 1), tf.argmax(y_test, 1))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "cur_test_acc = accuracy.numpy()\n",
        "print('\\nTest Accuracy: {:.2f}'.format(cur_test_acc))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "BatchNormPost_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}